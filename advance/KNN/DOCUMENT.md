# 1. KNN lÃ  gÃ¬?

**K-Nearest Neighbors (KNN)** lÃ  má»™t thuáº­t toÃ¡n **Machine Learning cÃ³ giÃ¡m sÃ¡t (supervised learning)**, dÃ¹ng cho:

- **Classification (phÃ¢n loáº¡i)**
- **Regression (há»“i quy)**

ğŸ‘‰ Ã tÆ°á»Ÿng:

> Má»™t Ä‘iá»ƒm dá»¯ liá»‡u má»›i sáº½ Ä‘Æ°á»£c gÃ¡n nhÃ£n dá»±a trÃªn **K Ä‘iá»ƒm gáº§n nÃ³ nháº¥t** trong táº­p dá»¯ liá»‡u huáº¥n luyá»‡n.

ğŸ“Œ KNN lÃ  **instance-based / lazy learning**

- KhÃ´ng há»c ra mÃ´ hÃ¬nh
- Chá»‰ lÆ°u toÃ n bá»™ dá»¯ liá»‡u
- Dá»± Ä‘oÃ¡n khi cÃ³ dá»¯ liá»‡u má»›i

---

# 2. Trá»±c giÃ¡c (Intuition)

Giáº£ sá»­:

- Báº¡n cÃ³ dá»¯ liá»‡u ngÆ°á»i dÃ¹ng: **tuá»•i â€“ thu nháº­p â€“ nghá»**
- Má»™t ngÆ°á»i má»›i xuáº¥t hiá»‡n
  â¡ï¸ Há»i: _â€œNgÆ°á»i nÃ y giá»‘ng ai nháº¥t?â€_

ğŸ‘‰ NhÃ¬n vÃ o **K ngÆ°á»i gáº§n nháº¥t**

- Classification â†’ bá» phiáº¿u (majority vote)
- Regression â†’ láº¥y trung bÃ¬nh

---

# 3. Quy trÃ¬nh hoáº¡t Ä‘á»™ng cá»§a KNN

1. Chá»n **K** (sá»‘ hÃ ng xÃ³m)
2. TÃ­nh **khoáº£ng cÃ¡ch** tá»« Ä‘iá»ƒm má»›i Ä‘áº¿n táº¥t cáº£ Ä‘iá»ƒm train
3. Sáº¯p xáº¿p theo khoáº£ng cÃ¡ch
4. Láº¥y **K Ä‘iá»ƒm gáº§n nháº¥t**
5. Dá»± Ä‘oÃ¡n:

   - Classification â†’ nhÃ£n phá»• biáº¿n nháº¥t
   - Regression â†’ trung bÃ¬nh (hoáº·c trung bÃ¬nh cÃ³ trá»ng sá»‘)

---

# 4. CÃ¡c loáº¡i khoáº£ng cÃ¡ch (Distance Metrics)

### 4.1 Euclidean Distance (phá»• biáº¿n nháº¥t)

[
d(x,y)=\sqrt{\sum (x_i - y_i)^2}
]

âœ”ï¸ Dá»¯ liá»‡u liÃªn tá»¥c
âŒ Nháº¡y vá»›i scale

---

### 4.2 Manhattan Distance

[
d(x,y)=\sum |x_i - y_i|
]

âœ”ï¸ Khi dá»¯ liá»‡u cÃ³ dáº¡ng lÆ°á»›i (grid)

---

### 4.3 Minkowski Distance

[
d(x,y)=\left(\sum |x_i-y_i|^p\right)^{1/p}
]

- p=1 â†’ Manhattan
- p=2 â†’ Euclidean

---

### 4.4 Cosine Distance

[
1 - \cos(\theta)
]

âœ”ï¸ Text, NLP
âœ”ï¸ KhÃ´ng quan tÃ¢m Ä‘á»™ lá»›n, chá»‰ quan tÃ¢m hÆ°á»›ng

---

# 5. KNN cho Classification

### CÃ¡ch dá»± Ä‘oÃ¡n

- Láº¥y **K Ä‘iá»ƒm gáº§n nháº¥t**
- Äáº¿m sá»‘ lÆ°á»£ng má»—i class
- Class nÃ o nhiá»u nháº¥t â†’ káº¿t quáº£

ğŸ“Œ CÃ³ thá»ƒ dÃ¹ng **weighted voting**:

- Äiá»ƒm cÃ ng gáº§n â†’ trá»ng sá»‘ cÃ ng cao

---

# 6. KNN cho Regression

### CÃ¡ch dá»± Ä‘oÃ¡n

- Trung bÃ¬nh giÃ¡ trá»‹ cá»§a K neighbors
- Hoáº·c:
  [
  \hat{y}=\frac{\sum w_i y_i}{\sum w_i}
  ]

---

# 7. Chá»n K nhÆ° tháº¿ nÃ o?

| K     | Há»‡ quáº£       |
| ----- | ------------ |
| K nhá» | Overfitting  |
| K lá»›n | Underfitting |

ğŸ“Œ Thá»±c táº¿:

- DÃ¹ng **cross-validation**
- ThÆ°á»ng thá»­ K = 3,5,7,9,â€¦

---

# 8. Chuáº©n hÃ³a dá»¯ liá»‡u (Ráº¤T QUAN TRá»ŒNG)

KNN **phá»¥ thuá»™c hoÃ n toÃ n vÃ o khoáº£ng cÃ¡ch**
â¡ï¸ **Báº®T BUá»˜C scale dá»¯ liá»‡u**

### CÃ¡c cÃ¡ch scale:

- Min-Max Scaling
- Standardization (Z-score)

âŒ KhÃ´ng scale â†’ feature lá»›n láº¥n Ã¡t feature nhá»

---

# 9. Äá»™ phá»©c táº¡p (Complexity)

### Training

- O(1) (chá»‰ lÆ°u dá»¯ liá»‡u)

### Prediction

- O(n Ã— d)

  - n: sá»‘ máº«u
  - d: sá»‘ feature

ğŸ“Œ Dataset lá»›n â†’ cháº­m

---

# 10. Æ¯u Ä‘iá»ƒm & NhÆ°á»£c Ä‘iá»ƒm

### âœ… Æ¯u Ä‘iá»ƒm

- Dá»… hiá»ƒu, dá»… cÃ i
- KhÃ´ng cáº§n training
- Hoáº¡t Ä‘á»™ng tá»‘t vá»›i dataset nhá»

### âŒ NhÆ°á»£c Ä‘iá»ƒm

- Ráº¥t cháº­m vá»›i dataset lá»›n
- Tá»‘n bá»™ nhá»›
- Nháº¡y vá»›i noise
- Nháº¡y vá»›i scale

---

# 11. So sÃ¡nh KNN vá»›i thuáº­t toÃ¡n khÃ¡c

| Thuáº­t toÃ¡n          | Äáº·c Ä‘iá»ƒm            |
| ------------------- | ------------------- |
| KNN                 | Dá»±a vÃ o khoáº£ng cÃ¡ch |
| Logistic Regression | Linear              |
| SVM                 | TÃ¬m hyperplane      |
| Decision Tree       | Rule-based          |
| Naive Bayes         | XÃ¡c suáº¥t            |

---

# 12. KNN trong scikit-learn (Python)

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

knn = KNeighborsClassifier(
    n_neighbors=5,
    metric='euclidean'
)
knn.fit(X_scaled, y)

y_pred = knn.predict(X_test_scaled)
```

---

# 13. CÃ¡c biáº¿n thá»ƒ cá»§a KNN

- **Weighted KNN**
- **Radius Neighbors**
- **Approximate KNN**
- **KD-Tree / Ball Tree**

---

# 14. Khi nÃ o nÃªn dÃ¹ng KNN?

âœ” Dataset nhá» â€“ trung bÃ¬nh
âœ” Feature sá»‘
âœ” KhÃ´ng cáº§n model interpretability cao
âŒ Dataset ráº¥t lá»›n
âŒ Feature nhiá»u chiá»u (curse of dimensionality)

---

# 15. CÃ¡c váº¥n Ä‘á» thÆ°á»ng gáº·p

- Curse of dimensionality
- Data imbalance
- Noise
- Feature irrelevant

---

# 16. Lá»™ trÃ¬nh há»c tiáº¿p theo

Náº¿u báº¡n há»c ML bÃ i báº£n:

1. KNN
2. Linear / Logistic Regression
3. Naive Bayes
4. Decision Tree
5. Random Forest
6. SVM
