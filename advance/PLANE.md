# ğŸ§­ ROADMAP Há»ŒC SCIKIT-LEARN (ÄÃƒ BIáº¾T NUMPY + PANDAS)

---

## ğŸ”¹ GIAI ÄOáº N 0 â€“ TÆ° duy ML (2â€“3 ngÃ y)

ğŸ‘‰ CÃ¡i nÃ y cá»±c quan trá»ng, nhiá»u ngÆ°á»i bá» qua

### Cáº§n hiá»ƒu:

- Supervised vs Unsupervised Learning
- Classification vs Regression
- Overfitting / Underfitting
- Train / Validation / Test
- Data Leakage lÃ  gÃ¬

ğŸ“Œ Output:

- Biáº¿t **khi nÃ o dÃ¹ng thuáº­t toÃ¡n nÃ o**
- Äá»c Ä‘Æ°á»£c pipeline ML

---

## ğŸ”¹ GIAI ÄOáº N 1 â€“ Workflow chuáº©n sklearn (Tuáº§n 1)

### 1.1 Cáº¥u trÃºc code ML chuáº©n

```python
model = Model()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
```

### 1.2 CÃ¡c bÆ°á»›c pháº£i náº¯m

- `train_test_split`
- `.fit()`, `.predict()`, `.score()`

### 1.3 Thá»±c hÃ nh

- Iris dataset
- Wine dataset

ğŸ“Œ Thuáº­t toÃ¡n:

- `LinearRegression`
- `LogisticRegression`

ğŸ¯ Output:

> Cháº¡y trÆ¡n tru 1 bÃ i ML tá»« A â†’ Z

---

## ğŸ”¹ GIAI ÄOáº N 2 â€“ Preprocessing & Feature (Tuáº§n 2)

### 2.1 Missing values

- `SimpleImputer`

### 2.2 Scaling (ráº¥t quan trá»ng)

- `StandardScaler`
- `MinMaxScaler`

### 2.3 Encoding

- `OneHotEncoder`
- `LabelEncoder` (chá»‰ dÃ¹ng cho y)

### 2.4 Feature Selection

- `SelectKBest`
- `VarianceThreshold`

ğŸ¯ BÃ i táº­p:

- Dataset cÃ³ cáº£ sá»‘ + chá»¯
- So sÃ¡nh **cÃ³ scale vs khÃ´ng scale**

---

## ğŸ”¹ GIAI ÄOáº N 3 â€“ Thuáº­t toÃ¡n cá»‘t lÃµi (Tuáº§n 3)

### 3.1 Classification

- KNN
- SVM
- Decision Tree
- Random Forest

### 3.2 Regression

- Ridge / Lasso
- SVR
- RandomForestRegressor

ğŸ“Œ So sÃ¡nh:

- Bias vs Variance
- Model Ä‘Æ¡n giáº£n vs phá»©c táº¡p

ğŸ¯ Output:

> Biáº¿t **vÃ¬ sao model nÃ y tá»‘t hÆ¡n model kia**

---

## ğŸ”¹ GIAI ÄOáº N 4 â€“ Evaluation & Validation (Tuáº§n 4)

### 4.1 Classification metrics

- Accuracy
- Precision / Recall
- F1-score
- Confusion Matrix
- ROC-AUC

### 4.2 Regression metrics

- MAE / MSE / RMSE
- RÂ²

### 4.3 Cross Validation

- `KFold`
- `StratifiedKFold`
- `cross_val_score`

ğŸ¯ Output:

> KhÃ´ng cÃ²n Ä‘Ã¡nh giÃ¡ model sai cÃ¡ch âŒ

---

## ğŸ”¹ GIAI ÄOáº N 5 â€“ Pipeline & Production mindset (Tuáº§n 5)

### 5.1 Pipeline

```python
Pipeline([
  ("scaler", StandardScaler()),
  ("model", LogisticRegression())
])
```

### 5.2 ColumnTransformer

- Numeric pipeline
- Categorical pipeline

ğŸ“Œ Táº¡i sao quan trá»ng?

- TrÃ¡nh data leakage
- Deploy Ä‘Æ°á»£c model

ğŸ¯ Output:

> Code ML **chuáº©n production**

---

## ğŸ”¹ GIAI ÄOáº N 6 â€“ Hyperparameter Tuning (Tuáº§n 6)

### 6.1 GridSearchCV

### 6.2 RandomizedSearchCV

ğŸ“Œ Hiá»ƒu:

- Hyperparameter vs parameter
- Overfitting khi tuning

ğŸ¯ Output:

> Biáº¿t tá»‘i Æ°u model Ä‘Ãºng cÃ¡ch

---

## ğŸ”¹ GIAI ÄOáº N 7 â€“ Mini Projects (Báº®T BUá»˜C)

### Project 1 â€“ Classification

- Predict khÃ¡ch hÃ ng churn
- Spam email
- Titanic survival

### Project 2 â€“ Regression

- House price prediction
- Student score prediction

ğŸ“Œ YÃªu cáº§u:

- EDA (pandas)
- Preprocessing
- Pipeline
- Evaluation
- Report káº¿t quáº£

---

# ğŸ§  Cheat Sheet â€“ Há»c tháº¿ nÃ o cho hiá»‡u quáº£?

âœ… 70% thá»i gian **code**
âœ… LuÃ´n há»i: _"Model nÃ y sai á»Ÿ Ä‘Ã¢u?"_
âŒ KhÃ´ng há»c deep learning vá»™i

---

# ğŸš€ Sau khi xong lá»™ trÃ¬nh nÃ y báº¡n cÃ³ thá»ƒ:

- Tá»± lÃ m ML project
- Hiá»ƒu paper ML cÆ¡ báº£n
- Chuyá»ƒn sang:

  - XGBoost / LightGBM
  - Deep Learning
  - MLOps
